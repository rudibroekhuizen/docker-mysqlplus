# Process PostgreSQL logs

input {
  file {
    path => "/mnt/data/*.log"
    type => "mysql_log"
  }
}

filter {
  if [type] == "mysql_log" {
    multiline {
      pattern => "^\s"
      what    => "previous"
    }
    grok {
      match        => { "message" => "start_prefix%{GREEDYDATA:log_line_prefix}end_prefix log_line: %{GREEDYDATA:log_line}" }
      remove_field => [ "message" ]
    }
    json {
      source       => log_line_prefix
      remove_field => [ "log_line_prefix" ]
    }
    mutate {
      gsub => [
        "log_time", ".{4}$", ""
      ]
    }
    date {
      match        => ["log_time", "yyyy-MM-dd HH:mm:ss.SSS"]
      remove_field => [ "log_time" ]
    }
    if [log_line] =~ "duration: " {
      grok {
        match => { "log_line" => "LOG:  duration: %{BASE10NUM:duration:float} ms  (statement: |execute <unnamed>: |parse <unnamed>: |bind <unnamed>: )%{GREEDYDATA:statement}" }
      }
    }
  }
}

output {
  elasticsearch {
    hosts => [ "elasticsearch" ]
    index => "logstash-mysql-%{+YYYY.MM.dd}"
  }
}
