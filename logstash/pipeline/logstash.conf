# Process MySQL general log:
# mysql -b -u root -p mysql -e "SELECT * from general_log" >> /tmp/general.log

# Process MySQL slow log:
# mysql -b -u root -p mysql -e "SELECT *, MICROSECOND(query_time) AS 'query_time_microseconds', MICROSECOND(lock_time) AS 'lock_time_microseconds' FROM slow_log" >> /tmp/slow.log

input {
  file {
    path => "/mnt/data/general.log"
    tags => [ "general_log" ]
  }
  file {
    path => "/mnt/data/slow.log"
    tags => [ "slow_log" ]
  }
}

filter {
  if "general_log" in [tags] {
    csv {
      separator => "	"
      columns => ["event_time", "user_host", "thread_id", "server_id", "command_type", "argument"]
    }
    date {
      match => ["event_time", "yyyy-MM-dd HH:mm:ss.SSSSSS", "yyyy-MM-dd HH:mm:ss"]
    }
  }
  if "slow_log" in [tags] {
    csv {
      separator => "	"
      columns => ["start_time", "user_host", "query_time_microseconds", "lock_time_microseconds", "rows_sent", "rows_examined", "db", "last_insert_id", "insert_id", "server_id", "sql_text", "thread_id"]
    }
    date {
      match => ["start_time", "yyyy-MM-dd HH:mm:ss.SSSSSS", "yyyy-MM-dd HH:mm:ss"]
    }
    mutate {
      convert => {
        "query_time_microseconds" => "integer"
        "lock_time_microseconds" => "integer"
        "rows_examined" => "integer"
      }
    }
  }
}

output {
  elasticsearch {
    hosts => [ "elasticsearch" ]
    index => "logstash-%{+YYYY.MM.dd}"
  }
}
