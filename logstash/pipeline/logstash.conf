# Process MySQL logs

input {
  file {
    path => "/mnt/data/general.log"
    type => "general_log"
  }
  file {
    path => "/mnt/data/slow.log"
    type => "slow_log"
  }
}

filter {
  if [type] == "general_log" {
    csv {
      separator => "	"
      columns => ["event_time", "user_host", "thread_id", "server_id", "command_type", "argument"]
    }
    date {
      match => ["event_time", "yyyy-MM-dd HH:mm:ss.SSSSSS"]
    }
  }
  if [type] == "slow_log" {
    csv {
      separator => "	"
      columns => ["start_time", "user_host", "query_time", "lock_time", "rows_sent", "rows_examined", "db", "last_insert_id", "insert_id", "server_id", "sql_text", "thread_id", "query_time_microseconds", "lock_time_microseconds"]
    }
    date {
      match => ["start_time", "yyyy-MM-dd HH:mm:ss.SSSSSS"]
    }
    mutate {
      convert => {
        "query_time_microseconds" => "integer"
	"lock_time_microseconds" => "integer"
      }
    }
  }
}

output {
  elasticsearch {
    hosts => [ "elasticsearch" ]
    index => "logstash1-mysql-%{+YYYY.MM.dd}"
  }
}
